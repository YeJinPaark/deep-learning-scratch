{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.6 CNN 시각화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.6.1 1번째 층의 가중치 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞선 예제에서\n",
    "    - 1번째 층의 `합성곱 계층의 가중치 형상`: (30, 1, 5, 5)  \n",
    "    $\\equiv$ 필터 30개, 채널 1개, 5*5 크기  \n",
    "\n",
    "        $\\to$ 필터의 크기가 5*5이고, 채널이 1개  \n",
    "    $\\equiv$ 해당 필터를 `1채널의 회색조 이미지`로 시각화할 수 있음\n",
    "\n",
    "    - 학습 전 필터: 무작위로 초기화되어 있음  \n",
    "    $\\equiv$ 흑백의 정도에 규칙성이 없음\n",
    "\n",
    "    - `학습을 마친 필터: 규칙성이 있는 이미지`\n",
    "    $\\equiv$ 흰색에서 검은색으로 점차 변화하는 필터와 bolb가 진 필터 등, 규칙을 띄는 필터로 변화  \n",
    "    $\\equiv$ edge(색상이 바뀐 경계선)와 bolb(국소적으로 덩어리진 영역)을 보고 있음\n",
    "\n",
    "    $\\to$ ex) 왼쪽 절반이 흰색, 오른쪽 절반이 검은색인 필터  \n",
    "    $\\equiv$ `세로 방향의 에지에 반응`하는 필터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.6.2 층 깊이에 따른 추출 정보 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1번째 층의 합성곱 계층  \n",
    "    - 에지나 블롭 등의 `저수준 정보` 추출\n",
    "\n",
    "- 겹겹이 쌓인 CNN의 각 계층  \n",
    "    - 계층이 깊어질수록, `추출되는 정보는 더 추상화`됨\n",
    "\n",
    "- ex) `AlexNet`: 일반 사물 인식(자동차나 개 등)을 수행한 8층의 CNN  \n",
    "    - 합성곱 계층과 풀링 계층을 여러 겹 쌓고,  \n",
    "    - 마지막으로 완전연결 계층을 거쳐 결과를 출력하는 구조  \n",
    "\n",
    "    - 처음 층: 단순한 에지에 반응  \n",
    "    - 이어서 텍스처, 복잡한 사물의 일부에 반응하도록\n",
    "    $\\equiv$ 층이 깊어지면서 뉴런이 반응하는 대상이 고급 정보로 변화  \n",
    "    $\\equiv$ `사물의 의미를 이해하도록` 변화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.7 대표적인 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.7.1 LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫 CNN\n",
    "- 손글씨 숫자를 인식하는 네트워크(`since 1998`)  \n",
    "    - 합성곱 계층과 풀링 계층(원소를 줄이는 역할만 수행하는 서브샘플링 계층) 반복  \n",
    "    $\\to$ 마지막으로 완전연결 계층을 거쳐 결과 출력\n",
    "    \n",
    "    - `활성화 함수`: 시그모이드\n",
    "    cf) 현재는 주로 ReLU 사용\n",
    "    - `풀링`: 서브샘플링을 하여 중간 데이터의 크기가 작아짐\n",
    "    cf) 현재는 최대 풀링이 주로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.7.2 AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 합성곱 계층과 풀링 계층을 거듭하고,  \n",
    "$\\to$ 마지막으로 완전연결 계층을 거쳐 결과 출력\n",
    "\n",
    "- 활성화 함수: ReLU  \n",
    "- `LRN(Local Response Nomalization)`: 국소적 정규화를 실시하는 계층 이용  \n",
    "- 드롭아웃 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.8 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN: 완전연결 계층 네트워크 + `합성곱 계층` + `풀링 계층`  \n",
    "- im2col: 이미지를 행렬로 전개하는 함수  \n",
    "        $\\to$ 합성곱 계층과 풀링 계층을 간단하고 효율적으로 구현\n",
    "        \n",
    "- 계층이 깊어질수록, 고급 정보가 추출됨\n",
    "- 대표적인 예: LeNet, AlexNet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28435c4127f67b7607031f32967fe3943e6f69f1a5ec9adab2b1e0962cf71e07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
