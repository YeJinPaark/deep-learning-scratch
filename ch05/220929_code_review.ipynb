{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.7.4 오차역전파법을 사용한 학습 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,10) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\a2322\\OneDrive\\바탕 화면\\220902_밑바닥부터 시작하는 딥러닝\\ch05\\220929_code_review.ipynb 셀 2\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/a2322/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/220902_%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/ch05/220929_code_review.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/a2322/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/220902_%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/ch05/220929_code_review.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmnist\u001b[39;00m \u001b[39mimport\u001b[39;00m load_mnist\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/a2322/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/220902_%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/ch05/220929_code_review.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtwo_layer_net\u001b[39;00m \u001b[39mimport\u001b[39;00m TwoLayerNet\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/a2322/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/220902_%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/ch05/220929_code_review.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# 데이터 읽기\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/a2322/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/220902_%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/ch05/220929_code_review.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m (x_train, t_train), (x_test, t_test) \u001b[39m=\u001b[39m load_mnist(normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, one_hot_label\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\a2322\\OneDrive\\바탕 화면\\220902_밑바닥부터 시작하는 딥러닝\\ch05\\two_layer_net.py:130\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m t_batch \u001b[39m=\u001b[39m t_train[:\u001b[39m3\u001b[39m]\n\u001b[0;32m    129\u001b[0m grad_numerical \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39mnumerical_gradient(x_batch, t_batch)\n\u001b[1;32m--> 130\u001b[0m grad_backprop \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39;49mgradient(x_batch, t_batch)\n\u001b[0;32m    133\u001b[0m \u001b[39m# 각 가중치의 절대 오차의 평균 연산\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m grad_numerical\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[1;32mc:\\Users\\a2322\\OneDrive\\바탕 화면\\220902_밑바닥부터 시작하는 딥러닝\\ch05\\two_layer_net.py:104\u001b[0m, in \u001b[0;36mTwoLayerNet.gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m# 역전파\u001b[39;00m\n\u001b[0;32m    103\u001b[0m dout \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 104\u001b[0m dout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlasyLayer\u001b[39m.\u001b[39;49mbackward(dout)\n\u001b[0;32m    106\u001b[0m layers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m    107\u001b[0m layers\u001b[39m.\u001b[39mreverse()\n",
      "File \u001b[1;32mc:\\Users\\a2322\\OneDrive\\바탕 화면\\220902_밑바닥부터 시작하는 딥러닝\\ch05\\two_layer_net.py:31\u001b[0m, in \u001b[0;36mSoftmaxWithLoss.backward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(\u001b[39mself\u001b[39m, dout\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     30\u001b[0m     batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 31\u001b[0m     dx \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt) \u001b[39m/\u001b[39m batch_size\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m dx\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,10) (3,) "
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 1000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 오차역전파법으로 기울기 연산\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "\n",
    "    # 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i%iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_test, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.8 정리\n",
    "    - 모든 계층에서 forward, backward 메서드 구현\n",
    "    - forward: 데이터를 순방향으로\n",
    "    - backward: 데이터를 역방향으로 전파함으로써 가중치 매개변수의 기울기를 효과적으로 학습\n",
    "\n",
    "    - 계산 그래프의 노드는 국소적 계산으로 구성되어 전체 계산 구성\n",
    "    - 계산 그래프의 순전파는 통상의 계산 수행\n",
    "    - 계산 그래프의 역전파는 각 노드의 미분 연산 가능\n",
    "\n",
    "    - 수치 미분과 오차역전파법의 결과를 비교하여 구현의 오류를 발견할 수 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28435c4127f67b7607031f32967fe3943e6f69f1a5ec9adab2b1e0962cf71e07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
