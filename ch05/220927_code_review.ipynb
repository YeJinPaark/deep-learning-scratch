{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.6.2배치용 Affine 계층\n",
    "    - 데이터 N개를 묶은 데이터인 '배치'로 순전파하는 경우\n",
    "    - 5.6.1의 예에서 X의 형상이 (N, 2)로 변한 것 외 동일\n",
    "\n",
    "    - aL/aX = aL/aY *W^T == (N,2) = (N,3) * (3,2)\n",
    "    - aL/aW = X^T * aL/aY == (2,3) = (2,N) * (N,3)\n",
    "    - aL/aB = aL/aY == (3) = (N,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0]\n",
      " [10 10 10]]\n",
      "[[ 1  2  3]\n",
      " [11 12 13]]\n"
     ]
    }
   ],
   "source": [
    "# 순전파의 경우, 편향은 N개의 데이터에 각각 더해짐\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_dot_W=np.array([[0, 0, 0], [10, 10, 10]])\n",
    "B=np.array([1, 2, 3])\n",
    "\n",
    "print(X_dot_W)\n",
    "print(X_dot_W + B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "# 역전파의 경우, 각 데이터의 역전파 값이 편향의 원소에 모여야 함\n",
    "\n",
    "dY=np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(dY)\n",
    "\n",
    "dB=np.sum(dY, axis=0)   # N개의 데이터에 대한 미분을 데이터마다 더해서 연산 ==0번째 축에 대한 총합 연산\n",
    "print(dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine 구현\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x =x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db - np.sum(dout, axis=0)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.6.3 Softmax-with-Loss 계층\n",
    "    - 출력층에서 사용하는 softmax 함수\n",
    "    - 교차 엔트로피 오차 포함한 소프트맥스 계층\n",
    "\n",
    "    - Softmax: 입력 값을 정규화하여 출력 (출력의 합이 1이 되도록 변형)\n",
    "\n",
    "    - 추론 시에, 사용 X/ 마지막 Affine 계층의 출력을 인식 결과로 이용\n",
    "    - 점수(score): Softmax 앞의 Affine 계층의 출력\n",
    "\n",
    "    - softmax는 주로 학습 시에 활용 \n",
    "\n",
    "    [교재 표기]\n",
    "    - an: 입력\n",
    "    - yn: 입력 an을 softmax로 정규화한 출력값\n",
    "    - tn: 정답 레이블\n",
    "    - L: softmax 계층의 출력과 정답 레이블을 입력으로 받아, cross entropy error 계층으로부터 손실 출력\n",
    "\n",
    "    - softmax의 역전파: softmax 계층 출력과 정답 레이블의 차분\n",
    "    == 신경망의 역전파에서 오차가 앞 계층에 전달되는 것을 의미\n",
    "    - but, 있는 그대로 전달하는 것은 오차를 그대로 드러내는 것\n",
    "\n",
    "    ex)\n",
    "    - 정답 레이블: (0, 1, 0)\n",
    "    - softmax 계층: (0.3, 0.2, 0.5)\n",
    "    - 역전파: (0.3, -0.8, 0.5)\n",
    "\n",
    "    - 정답 레이블: (0, 1, 0)\n",
    "    - softmax 계층: (0.01, 0.99, 0)\n",
    "    - 역전파: (0.01, -0.01, 0)\n",
    "    -> 오차가 작아졌으니, 학습하는 정도도 줄어듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax 구현(3.5.2 참고)\n",
    "\n",
    "def softmax(a):\n",
    "    c=np.max(a)\n",
    "    exp_a=np.exp(a-c) # 오버플로 방지\n",
    "    sum_exp_a=np.sum(exp_a)\n",
    "    y=exp_a/sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy_error() 구현(4.2.2 참고)\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    delta=1e-7\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax 구현\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None        # 손실\n",
    "        self.y= None            # softmax의 출력\n",
    "        self.t = None           # 정답 레이블(원-핫 벡터)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    # 역전파의 경우, 전파하는 값을 배치의 수로 나누어 데이터 1개당 오차를 앞 계층으로 전파\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28435c4127f67b7607031f32967fe3943e6f69f1a5ec9adab2b1e0962cf71e07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
